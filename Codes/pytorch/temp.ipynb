{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.13.1\n",
      "torchvision version: 0.14.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.FashionMNIST(root='data', train=True, download=True, transform=to_tensor)\n",
    "test_data = datasets.FashionMNIST(root='data', train=False, download=True, transform=to_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n",
    "# test_loader = DataLoader(dataset=test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model0(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear): Linear(in_features=784, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model0(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "model0 = Model0()\n",
    "model0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model0.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_train import TorchTrain\n",
    "from torchmetrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = Accuracy(task = 'multiclass', num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MulticlassAccuracy'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc._get_name()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchmetrics.classification.accuracy.MulticlassAccuracy"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'accuracy': acc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = TorchTrain(model0, optimizer, loss, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MulticlassAccuracy'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc._get_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MulticlassAccuracy()'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/ 5 Batch 1875/1875[====================] Train loss: 0.5902 | Train Accuracy: 0.8032\n",
      "Epoch    1/   5[========------------] Test loss: 0.5031 | Test Accuracy: 0.8292\n",
      "Epoch  2/ 5 Batch 1875/1875[====================] Train loss: 0.4607 | Train Accuracy: 0.8430\n",
      "Epoch    2/   5[============--------] Test loss: 0.4768 | Test Accuracy: 0.8363\n",
      "Epoch  3/ 5 Batch 1875/1875[====================] Train loss: 0.4325 | Train Accuracy: 0.8515\n",
      "Epoch    3/   5[================----] Test loss: 0.4628 | Test Accuracy: 0.8343\n",
      "Epoch  4/ 5 Batch 1875/1875[====================] Train loss: 0.4224 | Train Accuracy: 0.8531\n",
      "Epoch    4/   5[====================] Test loss: 0.4550 | Test Accuracy: 0.8415\n",
      "Epoch  5/ 5 Batch 1875/1875[====================] Train loss: 0.4121 | Train Accuracy: 0.8566\n",
      "Epoch    5/   5[========================] Test loss: 0.4583 | Test Accuracy: 0.8410\n"
     ]
    }
   ],
   "source": [
    "tt.fit(train_loader, test_loader, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, loss_fn, optimizer, x, y):\n",
    "    model.train()\n",
    "    yhat = model(x)\n",
    "    l = loss_fn(yhat, y)\n",
    "    optimizer.zero_grad()\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    return l.item()\n",
    "\n",
    "def test_step(model, loss_fn, x, y):\n",
    "    model.eval()\n",
    "    yhat = model(x)\n",
    "    l = loss_fn(yhat, y)\n",
    "    return l.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, x, y):\n",
    "    model.eval()\n",
    "    yhat = model(x)\n",
    "    yhat = torch.argmax(yhat, dim=1)\n",
    "    return torch.sum(yhat == y).item() / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1/ 5 | Train Loss: 0.4069 | Train Acc: 1.0000 | Test Loss: 0.4584 | Test Acc: 0.8750\n",
      "Epoch:  2/ 5 | Train Loss: 0.4010 | Train Acc: 0.8125 | Test Loss: 0.4449 | Test Acc: 0.8750\n",
      "Epoch:  3/ 5 | Train Loss: 0.3982 | Train Acc: 0.7812 | Test Loss: 0.4456 | Test Acc: 0.8750\n",
      "Epoch:  4/ 5 | Train Loss: 0.3937 | Train Acc: 0.8125 | Test Loss: 0.4428 | Test Acc: 0.8750\n",
      "Epoch:  5/ 5 | Train Loss: 0.3908 | Train Acc: 0.9062 | Test Loss: 0.4607 | Test Acc: 0.8125\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = 0\n",
    "    test_loss = 0\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        train_loss += train_step(model0, loss, optimizer, x, y)\n",
    "        print(f\"Epoch: {epoch+1:>2d}/{EPOCHS:>2d} | Batch: {i+1:>3d}/{len(train_loader):>3d} | Loss: {train_loss/(i+1):.4f}\", end='\\r')\n",
    "    train_acc = accuracy(model0, x, y)\n",
    "    for x, y in test_loader:\n",
    "        test_loss += test_step(model0, loss, x, y)\n",
    "    test_acc = accuracy(model0, x, y)\n",
    "    train_loss /= len(train_loader)\n",
    "    test_loss /= len(test_loader)\n",
    "    print(f\"Epoch: {epoch+1:>2d}/{EPOCHS:>2d} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, x):\n",
    "    model.eval()\n",
    "    yhat = model(x)\n",
    "    yhat = torch.argmax(yhat, dim=1)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m x, y \u001b[39m=\u001b[39m test_data[\u001b[39m0\u001b[39m]\n\u001b[1;32m      7\u001b[0m yhat \u001b[39m=\u001b[39m predict(model0, x\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m))\n\u001b[0;32m----> 8\u001b[0m plot_sample(x, y, yhat, classes)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classes' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_sample(x, y, yhat, classes):\n",
    "    plt.imshow(x.squeeze(), cmap='binary')\n",
    "    plt.title(f\"Label: {classes[y]}\\nPrediction: {classes[yhat]}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "x, y = test_data[0]\n",
    "yhat = predict(model0, x.unsqueeze(0))\n",
    "plot_sample(x, y, yhat, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1(nn.Module):\n",
    "    def __init__(self, color_channel: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=color_channel, \n",
    "                      out_channels=hidden_units, \n",
    "                      kernel_size=3, # how big is the square that's going over the image?\n",
    "                      stride=1, # default\n",
    "                      padding=1),# options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, \n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride=2) # default stride value is same as kernel_size\n",
    "        )\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # Where did this in_features shape come from? \n",
    "            # It's because each layer of our network compresses and changes the shape of our inputs data.\n",
    "            nn.Linear(in_features=hidden_units*7*7, \n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.block_1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.block_2(x)\n",
    "        # print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        # print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv1(\n",
       "  (block_1): Sequential(\n",
       "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block_2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model = Conv1(1, 10, 10)\n",
    "conv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1/ 5 | Train Loss: 0.5193 | Train Acc: 0.7812 | Test Loss: 0.4016 | Test Acc: 0.8750\n",
      "Epoch:  2/ 5 | Train Loss: 0.3437 | Train Acc: 0.8438 | Test Loss: 0.3402 | Test Acc: 0.8750\n",
      "Epoch:  3/ 5 | Train Loss: 0.3028 | Train Acc: 0.9688 | Test Loss: 0.3310 | Test Acc: 0.9375\n",
      "Epoch:  4/ 5 | Train Loss: 0.2796 | Train Acc: 0.9062 | Test Loss: 0.2960 | Test Acc: 0.8125\n",
      "Epoch:  5/ 5 | Train Loss: 0.2632 | Train Acc: 0.9375 | Test Loss: 0.2830 | Test Acc: 0.8125\n"
     ]
    }
   ],
   "source": [
    "conv_loss = nn.CrossEntropyLoss()\n",
    "conv_optimizer = torch.optim.Adam(conv_model.parameters(), lr=0.001)\n",
    "\n",
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = 0\n",
    "    test_loss = 0\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        train_loss += train_step(conv_model, conv_loss, conv_optimizer, x, y)\n",
    "        print(f\"Epoch: {epoch+1:>2d}/{EPOCHS:>2d} | Batch: {i+1:>3d}/{len(train_loader):>3d} | Loss: {train_loss/(i+1):.4f}\", end='\\r')\n",
    "    train_acc = accuracy(conv_model, x, y)\n",
    "    for x, y in test_loader:\n",
    "        test_loss += test_step(conv_model, conv_loss, x, y)\n",
    "    test_acc = accuracy(conv_model, x, y)\n",
    "    train_loss /= len(train_loader)\n",
    "    test_loss /= len(test_loader)\n",
    "    print(f\"Epoch: {epoch+1:>2d}/{EPOCHS:>2d} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2efee1efa502125d01e6b4768ba06d9453d29f3642bfd14ad5d4a769de82e88c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
