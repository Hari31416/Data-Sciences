{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To establish notation for future use, we’ll use $x^{(i)}x$ to denote the “input” variables (living area in this example), also called input features, and $y^{(i)}y$ to denote the “output” or target variable that we are trying to predict (price). A pair $(x^{(i)}$ , $y^{(i)} )$ is called a training example, and the dataset that we’ll be using to learn—a list of m training examples ${(x^{(i)} , y^{(i)} ); i = 1, . . . , m}$ is called a training set. \n",
    "<br>\n",
    "To describe the supervised learning problem slightly more formally, our goal is, given a training set, to learn a function $h : X → Y$ so that $h(x)$ is a “good” predictor for the corresponding value of y. For historical reasons, this function h is called a hypothesis. <br> <br>\n",
    "<img src=\"img/cf_1.png\" width=\"400\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function\n",
    "We can measure the accuracy of our hypothesis function by using a cost function. This takes an average difference (actually a fancier version of an average) of all the results of the hypothesis with inputs from x's and the actual output y's.\n",
    "\n",
    "$$J(\\theta_0, \\theta_1) = \\dfrac {1}{2m} \\displaystyle \\sum _{i=1}^m \\left ( \\hat{y}_{i}- y_{i} \\right)^2 = \\dfrac {1}{2m} \\displaystyle \\sum _{i=1}^m \\left (h_\\theta (x_{i}) - y_{i} \\right)^2\n",
    "$$\n",
    "To break it apart, it is $\\frac{1}{2}\\bar{x}$ where $\\bar{x}$ is the mean of the squares of $h_\\theta (x_{i}) - y_{i}$ or the difference between the predicted value and the actual value.\n",
    "<br>\n",
    "This function is otherwise called the \"Squared error function\", or \"Mean squared error\". The mean is halved $\\left(\\frac{1}{2}\\right)$ as a convenience for the computation of the gradient descent, as the derivative term of the square function will cancel out the $\\frac{1}{2}$ term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "Imagine that we graph our hypothesis function based on its fields $\\theta_0$ and $\\theta_1$ (actually we are graphing the cost function as a function of the parameter estimates). The way we get the values of $\\theta_0$ and $\\theta_1$ is by using gradient descent. We take the derivative (the tangential line to a function) of our cost function. The slope of the tangent is the derivative at that point and it will give us a direction to move towards. We make steps down the cost function in the direction with the steepest descent. The size of each step is determined by the parameter $\\alpha$, which is called the learning rate.\n",
    "<br>\n",
    "The gradient descent algorithm is:\n",
    "<br>\n",
    "repeat until convergence:\n",
    "\n",
    "$$\\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j} J(\\theta_0, \\theta_1)$$\n",
    "where j=0,1 represents the feature index number.\n",
    "<br>\n",
    "At each iteration j, one should simultaneously update the parameters $\\theta_1, \\theta_2,...,\\theta_n$ . Updating a specific parameter prior to calculating another one on the $j^{(th)}$ iteration would yield to a wrong implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce44b17c45080b8f56a19c9450d52461d624c968fcd959bb1916985c5ffa2b94"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
