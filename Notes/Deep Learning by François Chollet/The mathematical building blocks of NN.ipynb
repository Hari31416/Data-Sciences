{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A first look at a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core building block of neural networks is the layer, a data-processing module that\n",
    "you can think of as a filter for data. Some data goes in, and it comes out in a more useful form. Specifically, layers extract representations out of the data fed into them—hopefully, representations that are more meaningful for the problem at hand. Most of\n",
    "deep learning consists of chaining together simple layers that will implement a form\n",
    "of progressive data distillation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the network ready for training, we need to pick three more things, as part\n",
    "of the compilation step:\n",
    "* A loss function—How the network will be able to measure its performance on\n",
    "the training data, and thus how it will be able to steer itself in the right direction.\n",
    "* An optimizer—The mechanism through which the network will update itself\n",
    "based on the data it sees and its loss function.\n",
    "* Metrics to monitor during training and testing—Here, we’ll only care about accuracy (the fraction of the images that were correctly classified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training, we’ll preprocess the data by reshaping it into the shape the network\n",
    "expects and scaling it so that all values are in the [0, 1] interval. Previously, our training images, for instance, were stored in an array of shape (60000, 28, 28) of type\n",
    "uint8 with values in the [0, 255] interval. We transform it into a float32 array of\n",
    "shape (60000, 28 * 28) with values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to categorically encode the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’re now ready to train the network, which in Keras is done via a call to the network’s `fit` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 24s 8ms/step - loss: 0.4371 - accuracy: 0.8732\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1123 - accuracy: 0.9673\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0698 - accuracy: 0.9789\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0506 - accuracy: 0.9849\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0358 - accuracy: 0.9884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23f1924e640>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0610 - accuracy: 0.9816\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data representations for neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example, we started from data stored in multidimensional Numpy\n",
    "arrays, also called tensors. In general, all current machine-learning systems use tensors\n",
    "as their basic data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalars (0D tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tensor that contains only one number is called a scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectors (1D tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An array of numbers is called a vector, or 1D tensor. A 1D tensor is said to have exactly\n",
    "one axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([12, 3, 6, 14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This vector has five entries and so is called a 5-dimensional vector. Don’t confuse a 5D\n",
    "vector with a 5D tensor! A 5D vector has only one axis and has five dimensions along its\n",
    "axis, whereas a 5D tensor has five axes (and may have any number of dimensions\n",
    "along each axis). Dimensionality can denote either the number of entries along a specific axis (as in the case of our 5D vector) or the number of axes in a tensor (such as a\n",
    "5D tensor), which can be confusing at times. In the latter case, it’s technically more\n",
    "correct to talk about a tensor of rank 5 (the rank of a tensor being the number of axes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrices (2D tensors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An array of vectors is a matrix, or 2D tensor. A matrix has two axes (often referred to\n",
    "rows and columns). You can visually interpret a matrix as a rectangular grid of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[5, 78, 2, 34, 0],\n",
    "    [6, 79, 3, 35, 1],\n",
    "    [7, 80, 4, 36, 2]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D tensors and higher-dimensional tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you pack such matrices in a new array, you obtain a 3D tensor, which you can visually\n",
    "interpret as a cube of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[[5, 78, 2, 34, 0],\n",
    "    [6, 79, 3, 35, 1],\n",
    "    [7, 80, 4, 36, 2]],\n",
    "    [[5, 78, 2, 34, 0],\n",
    "    [6, 79, 3, 35, 1],\n",
    "    [7, 80, 4, 36, 2]],\n",
    "    [[5, 78, 2, 34, 0],\n",
    "    [6, 79, 3, 35, 1],\n",
    "    [7, 80, 4, 36, 2]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tensor is defined by three key attributes:\n",
    "* **Number of axes (rank)**—For instance, a 3D tensor has three axes, and a matrix has\n",
    "two axes. This is also called the tensor’s ndim in Python libraries such as Numpy.\n",
    "* **Shape**—This is a tuple of integers that describes how many dimensions the tensor has along each axis. For instance, the previous matrix example has shape\n",
    "(3, 5), and the 3D tensor example has shape (3, 3, 5). A vector has a shape\n",
    "with a single element, such as (5,), whereas a scalar has an empty shape, ().\n",
    "* **Data type (usually called dtype in Python libraries)**—This is the type of the data\n",
    "contained in the tensor; for instance, a tensor’s type could be float32, uint8,\n",
    "float64, and so on. On rare occasions, you may see a char tensor. Note that\n",
    "string tensors don’t exist in Numpy (or in most other libraries), because tensors\n",
    "live in preallocated, contiguous memory segments: and strings, being variable\n",
    "length, would preclude the use of this implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating tensors in Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting specific elements in a tensor is called tensor slicing.\n",
    "Let’s look at the tensor-slicing operations you can do on Numpy arrays.\n",
    "The following example selects digits #10 to #100 (#100 isn’t included) and puts\n",
    "them in an array of shape (90, 28, 28):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s equivalent to this more detailed notation, which specifies a start index and stop\n",
    "index for the slice along each tensor axis. Note that : is equivalent to selecting the\n",
    "entire axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100, :, :]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100, 0:28, 0:28]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, you may select between any two indices along each tensor axis. For\n",
    "instance, in order to select 14 × 14 pixels in the bottom-right corner of all images, you\n",
    "do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 14, 14)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice= train_images[:, 14:, 14:]\n",
    "my_slice = train_images[:, 7:-7, 7:-7]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The notion of data batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the first axis (axis 0, because indexing starts at 0) in all data tensors you’ll\n",
    "come across in deep learning will be the samples axis (sometimes called the samples\n",
    "dimension). In the MNIST example, samples are images of digits.\n",
    "\n",
    "In addition, deep-learning models don’t process an entire dataset at once; rather,\n",
    "they break the data into small batches. When considering such a batch tensor, the first axis (axis 0) is called the batch axis or\n",
    "batch dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-world examples of data tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data you’ll manipulate will almost always fall into one of the following categories:\n",
    "* **Vector data**—2D tensors of shape *(samples, features)*\n",
    "* **Timeseries data or sequence data**—3D tensors of shape *(samples, timesteps,\n",
    "features)*\n",
    "* **Images**—4D tensors of shape *(samples, height, width, channels)* or *(samples,\n",
    "channels, height, width)*\n",
    "* **Video**—5D tensors of shape *(samples, frames, height, width, channels)* or\n",
    "*(samples, frames, channels, height, width)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most common case. In such a dataset, each single data point can be encoded\n",
    "as a vector, and thus a batch of data will be encoded as a 2D tensor (that is, an array of\n",
    "vectors), where the first axis is the samples axis and the second axis is the features axis.\n",
    "Let’s take a look at two examples:\n",
    "* An actuarial dataset of people, where we consider each person’s age, ZIP code,\n",
    "and income. Each person can be characterized as a vector of 3 values, and thus\n",
    "an entire dataset of 100,000 people can be stored in a 2D tensor of shape\n",
    "(100000, 3).\n",
    "* A dataset of text documents, where we represent each document by the counts\n",
    "of how many times each word appears in it (out of a dictionary of 20,000 common words). Each document can be encoded as a vector of 20,000 values (one\n",
    "count per word in the dictionary), and thus an entire dataset of 500 documents\n",
    "can be stored in a tensor of shape (500, 20000)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeseries data or sequence data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever time matters in your data (or the notion of sequence order), it makes sense\n",
    "to store it in a 3D tensor with an explicit time axis. Each sample can be encoded as a\n",
    "sequence of vectors (a 2D tensor), and thus a batch of data will be encoded as a 3D\n",
    "tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time axis is always the second axis (axis of index 1), by convention. Let’s look at a\n",
    "few examples:\n",
    "* A dataset of stock prices. Every minute, we store the current price of the stock,\n",
    "the highest price in the past minute, and the lowest price in the past minute.\n",
    "Thus every minute is encoded as a 3D vector, an entire day of trading is\n",
    "encoded as a 2D tensor of shape (390, 3) (there are 390 minutes in a trading\n",
    "day), and 250 days’ worth of data can be stored in a 3D tensor of shape (250,\n",
    "390, 3). Here, each sample would be one day’s worth of data.\n",
    "* A dataset of tweets, where we encode each tweet as a sequence of 280 characters\n",
    "out of an alphabet of 128 unique characters. In this setting, each character can\n",
    "be encoded as a binary vector of size 128 (an all-zeros vector except for a 1 entry\n",
    "at the index corresponding to the character). Then each tweet can be encoded\n",
    "as a 2D tensor of shape (280, 128), and a dataset of 1 million tweets can be\n",
    "stored in a tensor of shape (1000000, 280, 128)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images typically have three dimensions: height, width, and color depth. Although\n",
    "grayscale images (like our MNIST digits) have only a single color channel and could\n",
    "thus be stored in 2D tensors, by convention image tensors are always 3D, with a onedimensional color channel for grayscale images. A batch of 128 grayscale images of\n",
    "size 256 × 256 could thus be stored in a tensor of shape (128, 256, 256, 1), and a\n",
    "batch of 128 color images could be stored in a tensor of shape (128, 256, 256, 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two conventions for shapes of images tensors: the channels-last convention\n",
    "(used by TensorFlow) and the channels-first convention (used by Theano). The TensorFlow machine-learning framework, from Google, places the color-depth axis at the\n",
    "end: (samples, height, width, color_depth). Meanwhile, Theano places the color\n",
    "depth axis right after the batch axis: (samples, color_depth, height, width). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video data is one of the few types of real-world data for which you’ll need 5D tensors.\n",
    "A video can be understood as a sequence of frames, each frame being a color image.\n",
    "Because each frame can be stored in a 3D tensor *(height, width, color_depth)*, a\n",
    "sequence of frames can be stored in a 4D tensor *(frames, height, width, color_\n",
    "depth)*, and thus a batch of different videos can be stored in a 5D tensor of shape\n",
    "*(samples, frames, height, width, color_depth)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All transformations learned\n",
    "by deep neural networks can be reduced to a handful of tensor operations applied to\n",
    "tensors of numeric data. For instance, it’s possible to add tensors, multiply tensors,\n",
    "and so on. Some tesnor operatations are element-wise, and others are matrix-wise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When possible, and if there’s no ambiguity, the smaller tensor will be broadcasted to\n",
    "match the shape of the larger tensor. Broadcasting consists of two steps:\n",
    "1. Axes (called broadcast axes) are added to the smaller tensor to match the ndim of\n",
    "the larger tensor.\n",
    "2. The smaller tensor is repeated alongside these new axes to match the full shape\n",
    "of the larger tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider X with shape (32, 10) and y with shape\n",
    "(10,). First, we add an empty first axis to y, whose shape becomes (1, 10). Then, we\n",
    "repeat y 32 times alongside this new axis, so that we end up with a tensor Y with shape\n",
    "(32, 10), where `Y[i, :] == y for i in range(0, 32)`. At this point, we can proceed to\n",
    "add X and Y, because they have the same shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With broadcasting, you can generally apply two-tensor element-wise operations if one\n",
    "tensor has shape (a, b, … n, n + 1, … m) and the other has shape (n, n + 1, … m). The\n",
    "broadcasting will then automatically happen for axes a through n - 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dot product between two vectors is a scalar and that only\n",
    "vectors with the same number of elements are compatible for a dot product.\n",
    "You can also take the dot product between a matrix x and a vector y, which returns\n",
    "a vector where the coefficients are the dot products between y and the rows of x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common applications may be the dot product between two matrices. You\n",
    "can take the dot product of two matrices x and `y (dot(x, y))` if and only if\n",
    "`x.shape[1] == y.shape[0]`. The result is a matrix with shape `(x.shape[0],\n",
    "y.shape[1])`, where the coefficients are the vector products between the rows of x\n",
    "and the columns of y. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping a tensor means rearranging its rows and columns to match a target shape.\n",
    "Naturally, the reshaped tensor has the same total number of coefficients as the initial\n",
    "tensor. Reshaping is best understood via simple examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[0., 1.],\n",
    "    [2., 3.],\n",
    "    [4., 5.]])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [2., 3.],\n",
       "       [4., 5.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape((6, 1))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [5.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A special case of reshaping that’s commonly encountered is transposition. Transposing a\n",
    "matrix means exchanging its rows and its columns, so that `x[i, :]` becomes `x[:, i]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 300)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.zeros((300, 20))\n",
    "x = np.transpose(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">You can interpret a neural network as a very complex geometric transformation in a high-dimensional space, implemented via a long series of simple steps. Imagine two sheets of colored\n",
    "paper: one red and one blue. Put one on top of the other. Now crumple them\n",
    "together into a small ball. That crumpled paper ball is your input data, and each sheet\n",
    "of paper is a class of data in a classification problem. What a neural network (or any\n",
    "other machine-learning model) is meant to do is figure out a transformation of the\n",
    "paper ball that would uncrumple it, so as to make the two classes cleanly separable\n",
    "again. With deep learning, this would be implemented as a series of simple transformations of the 3D space, such as those you could apply on the paper ball with your fingers, one movement at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient-based Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each neural layer from our first network example\n",
    "transforms its input data as follows:<br>\n",
    "`output = relu(dot(W, input) + b)`<br>\n",
    "In this expression, W and b are tensors that are attributes of the layer. They’re called\n",
    "the weights or trainable parameters of the layer (the kernel and bias attributes, respectively). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, these weight matrices are filled with small random values (a step called random initialization). Of course, there’s no reason to expect that the output, will yield any useful representations. The resulting representations are meaningless—but they’re a starting point. What comes next is to gradually\n",
    "adjust these weights, based on a feedback signal. This gradual adjustment, also called\n",
    "training, is basically the learning that machine learning is all about.\n",
    "This happens within what’s called a training loop, which works as follows. Repeat\n",
    "these steps in a loop, as long as necessary:\n",
    "1. Draw a batch of training samples x and corresponding targets y.\n",
    "2. Run the network on x (a step called the forward pass) to obtain predictions y_pred.\n",
    "3. Compute the loss of the network on the batch, a measure of the mismatch\n",
    "between y_pred and y.\n",
    "4. Update all weights of the network in a way that slightly reduces the loss on this\n",
    "batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To upadet the weights, one naive solution would be to freeze all weights in the network except the one\n",
    "scalar coefficient being considered, and try different values for this coefficient. But such an approach would be horribly inefficient, because you’d need to compute two forward passes (which are expensive) for every individual coefficient (of\n",
    "which there are many, usually thousands and sometimes up to millions). A much better approach is to take advantage of the fact that all operations used in the network\n",
    "are differentiable, and compute the gradient of the loss with regard to the network’s\n",
    "coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a differentiable function, it’s theoretically possible to find its minimum analytically: it’s known that a function’s minimum is a point where the derivative is 0, so all\n",
    "you have to do is find all the points where the derivative goes to 0 and check for which\n",
    "of these points the function has the lowest value. However, solving for the zeros directly is not very easy. Instead, you can use the four-step algorithm outlined at the beginning of this section: modify the parameters little by little based on the current loss value on a random batch of data. Because you’re dealing with a differentiable function, you can\n",
    "compute its gradient, which gives you an efficient way to implement step 4. If you\n",
    "update the weights in the opposite direction from the gradient, the loss will be a little\n",
    "less every time:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Move the parameters a little in the opposite direction from the gradient—fo\n",
    "example $W -= step * gradient$ —thus reducing the loss on the batch a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Backpropagation algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neural network function\n",
    "consists of many tensor operations chained together, each of which has a simple,\n",
    "known derivative. Applying the chain rule to the\n",
    "computation of the gradient values of a neural network gives rise to an algorithm called Backpropagation (also sometimes called reverse-mode differentiation). Backpropagation starts with the final loss value and works backward from the top layers to the bottom layers, applying the chain rule to compute the contribution that each parameter\n",
    "had in the loss value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* Learning means finding a combination of model parameters that minimizes a loss function for a given set of training data samples and their corresponding targets.\n",
    ">* Learning happens by drawing random batches of data samples and their\n",
    "targets, and computing the gradient of the network parameters with\n",
    "respect to the loss on the batch. The network parameters are then moved\n",
    "a bit (the magnitude of the move is defined by the learning rate) in the\n",
    "opposite direction from the gradient.\n",
    ">* The entire learning process is made possible by the fact that neural networks are chains of differentiable tensor operations, and thus it’s possible\n",
    "to apply the chain rule of derivation to find the gradient function mapping the current parameters and current batch of data to a gradient value.\n",
    ">* Two key concepts you’ll see frequently in future chapters are loss and optimizers. These are the two things you need to define before you begin feeding data into a network.\n",
    ">* The loss is the quantity you’ll attempt to minimize during training, so it\n",
    "should represent a measure of success for the task you’re trying to solve.\n",
    ">* The optimizer specifies the exact way in which the gradient of the loss will\n",
    "be used to update parameters: for instance, it could be the RMSProp optimizer, SGD with momentum, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce44b17c45080b8f56a19c9450d52461d624c968fcd959bb1916985c5ffa2b94"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
