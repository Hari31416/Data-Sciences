{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Birds inspired us to fly, burdock plants inspired velcro, and countless more inven‐\n",
    "tions were inspired by nature. It seems only logical, then, to look at the brain’s archi‐\n",
    "tecture for inspiration on how to build an intelligent machine. This is the key idea\n",
    "that sparked artificial neural networks (ANNs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mlt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Biological to Artificial Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANNs have been around for quite a while. But everytime it enetred an era of long winter. We are now witnessing yet another wave of interest in ANNs. However, there a few good reasons to believe that\n",
    "this wave is different and that it will have a much more profound impact on our lives. Such as:\n",
    "* Large amounts of data\n",
    "* Increase in computational power\n",
    "* New training algorithms\n",
    "* Some theoretical limitations of ANNs have turned out to be benign in practice.\n",
    "For example, many people thought that ANN training algorithms were doomed\n",
    "because they were likely to get stuck in local optima, but it turns out that this is\n",
    "rather rare in practice (or when it is the case, they are usually fairly close to the\n",
    "global optimum)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biological Neurons and Logical Computation with Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<figcaption><h4>Biological neuron</h4></figcaption>\n",
    "<img src = \"img/10_01.png\">\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warren McCulloch and Walter Pitts proposed a very simple model of the biological\n",
    "neuron, which later became known as an artificial neuron: it has one or more binary\n",
    "(on/off) inputs and one binary output. The artificial neuron simply activates its out‐\n",
    "put when more than a certain number of its inputs are active. McCulloch and Pitts\n",
    "showed that even with such a simplified model it is possible to build a network of\n",
    "artificial neurons that computes any logical proposition you want. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<figcaption><h4>ANNs performing simple logical computations</h4></figcaption>\n",
    "<img src = \"img/10_02.png\">\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The working of first three networks is obvoius. The fourth network, on the other hand, computes a\n",
    "slightly more complex logical proposition: neuron C is activated only if neuron A\n",
    "is active and if neuron B is off. If neuron A is active all the time, then you get a\n",
    "logical NOT: neuron C is active when neuron B is off, and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Perceptron is one of the simplest ANN architectures, invented in 1957 by Frank\n",
    "Rosenblatt. It is based on a slightly different artificial neuron called a threshold logic unit (TLU), or sometimes a linear threshold unit (LTU): the inputs\n",
    "and output are now numbers (instead of binary on/off values) and each input con‐\n",
    "nection is associated with a weight. The TLU computes a weighted sum of its inputs\n",
    "($z = w_1 x_1 + w_2 x_2 + ⋯ + w_n x_n = \\mathbf{x}^T\\mathbf{w}$), then applies a step function to that sum and\n",
    "outputs the result: $h_w(\\mathbf{x}) = step(z)$, where $\\mathbf{x}^T\\mathbf{w}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<figcaption><h4>Threshold logic unit</h4></figcaption>\n",
    "<img src = \"img/10_03.png\">\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common step function used in Perceptrons is the Heaviside step function or sign function. It is defined as:\n",
    "$$h_w(z) = \\begin{cases}\n",
    "0 & \\text{if } z < 0 \\\\\n",
    "1 & \\text{if } z \\geq 0\n",
    "\\end{cases}$$\n",
    "And\n",
    "$$sgn(z) = \\begin{cases}\n",
    "-1 & \\text{if } z < 0 \\\\\n",
    "0 & \\text{if } z = 0 \\\\\n",
    "1 & \\text{if } z \\geq 0\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single TLU can be used for simple linear binary classification. It computes a linear\n",
    "combination of the inputs and if the result exceeds a threshold, it outputs the positive\n",
    "class or else outputs the negative class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Perceptron is simply composed of a single layer of TLUs, with each TLU connected\n",
    "to all the inputs. When all the neurons in a layer are connected to every neuron in the\n",
    "previous layer (i.e., its input neurons), it is called a fully connected layer or a dense\n",
    "layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<figcaption><h4>Perceptron diagram</h4></figcaption>\n",
    "<img src = \"img/10_04.png\">\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs of a fully connected layer simply is:\n",
    "$$ h_{\\mathbf{W, b}}(\\mathbf{X}) = \\phi(\\mathbf{XW+b}) $$\n",
    "With symols having the usual meaning. The $\\phi$ is called the *activation function*, when the artificial neurons are\n",
    "TLUs, it is a step function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way the Perceptron learns is:<br>\n",
    "The Perceptron is fed one\n",
    "training instance at a time, and for each instance it makes its predictions. For every\n",
    "output neuron that produced a wrong prediction, it reinforces the connection\n",
    "weights from the inputs that would have contributed to the correct prediction. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<figcaption><h4>Perceptron learning rule</h4></figcaption>\n",
    "<img src = \"img/10_05.png\">\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The decision boundary of each output neuron is linear, so Perceptrons are incapable\n",
    "of learning complex patterns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn provides a `Perceptron` class that implements a single TLU network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)]\n",
    "y = (iris.target == 0).astype(np.int)\n",
    "per_clf = Perceptron()\n",
    "per_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_clf.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting! ):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Scikit-Learn’s `Perceptron` class is equivalent\n",
    "to using an `SGDClassifier` with the following hyperparameters: `loss=\"perceptron\"`,\n",
    "`learning_rate=\"constant\"`, `eta0=1` (the learning rate), and `penalty=None` (no regu‐\n",
    "larization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A perceptron has a some serious limitations. For example, they are incapable of solving some trivial problems (e.g., the Exclusive OR (XOR) classification problem. However, it turns out that some of the limitations of Perceptrons can be eliminated by\n",
    "stacking multiple Perceptrons. The resulting ANN is called a Multi-Layer Perceptron\n",
    "(MLP). In particular, an MLP can solve the XOR problem, as you can verify by computing the output of the MLP represented:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<figcaption><h4>XOR classification problem and an MLP that solves it</h4></figcaption>\n",
    "<img src = \"img/10_06.png\">\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Layer Perceptron and Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An MLP is composed of one (passthrough) input layer, one or more layers of TLUs,\n",
    "called hidden layers, and one final layer of TLUs called the output layer. The layers close to the input layer are usually called the lower layers,\n",
    "and the ones close to the outputs are usually called the upper layers. Every layer\n",
    "except the output layer includes a bias neuron and is fully connected to the next layer. When an ANN contains a deep stack of hidden layers8, it is called a deep neural net‐\n",
    "work (DNN). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<figcaption><h4>Multi-Layer Perceptron</h4></figcaption>\n",
    "<img src = \"img/10_07.png\">\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm by which an MLP is trained is backpropogation. The steps are:\n",
    "* It handles one mini-batch at a time (for example containing 32 instances each),\n",
    "and it goes through the full training set multiple times. Each pass is called an\n",
    "epoch.\n",
    "*  Each mini-batch is passed to the network’s input layer, which just sends it to the\n",
    "first hidden layer. The algorithm then computes the output of all the neurons in\n",
    "this layer (for every instance in the mini-batch). The result is passed on to the\n",
    "next layer, its output is computed and passed to the next layer, and so on until we\n",
    "get the output of the last layer, the output layer. This is the forward pass: it is\n",
    "exactly like making predictions, except all intermediate results are preserved\n",
    "since they are needed for the backward pass.\n",
    "* Next, the algorithm measures the network’s output error.\n",
    "* Then it computes how much each output connection contributed to the error.\n",
    "* The algorithm then measures how much of these error contributions came from\n",
    "each connection in the layer below, until\n",
    "the algorithm reaches the input layer. This reverse pass\n",
    "efficiently measures the error gradient across all the connection weights in the network by propagating the error gradient backward through the network.\n",
    "* Finally, the algorithm performs a Gradient Descent step to tweak all the connec‐\n",
    "tion weights in the network, using the error gradients it just computed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To summarize: for each training\n",
    "instance the backpropagation algorithm first makes a prediction (forward pass),\n",
    "measures the error, then goes through each layer in reverse to measure the error contribution from each connection (reverse pass), and finally slightly tweaks the connection weights to reduce the error (Gradient Descent step)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> It is important to initialize all the hidden layers’ connection weights\n",
    "randomly, or else training will fail. For example, if you initialize all\n",
    "weights and biases to zero, then all neurons in a given layer will be\n",
    "perfectly identical, and thus backpropagation will affect them in\n",
    "exactly the same way, so they will remain identical. In other words,\n",
    "despite having hundreds of neurons per layer, your model will act\n",
    "as if it had only one neuron per layer: it won’t be too smart. If\n",
    "instead you randomly initialize the weights, you break the symmetry and allow backpropagation to train a diverse team of neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for this algorithm to work properly, the authors made a key change to the\n",
    "MLP’s architecture: they replaced the step function with the logistic function, $σ(z) =\n",
    "1 / (1 + exp(–z))$. This was essential because the step function contains only flat seg‐\n",
    "ments, so there is no gradient to work with (Gradient Descent cannot move on a flat\n",
    "surface), while the logistic function has a well-defined nonzero derivative every‐\n",
    "where, allowing Gradient Descent to make some progress at every step. In fact, the\n",
    "backpropagation algorithm works well with many other activation functions, not just\n",
    "the logistic function. Two of these are:\n",
    "* The hyperbolic tangent function $tanh(z) = 2σ(2z) – 1$\n",
    "* The Rectified Linear Unit function: $ReLU(z) = max(0, z)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<figcaption><h4>Activation functions and their derivatives</h4></figcaption>\n",
    "<img src = \"img/10_08.png\">\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression MLPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLPs can be used for regression tasks. (No surprise!). For multivariate regression (i.e., to predict\n",
    "multiple values at once), you need one output neuron per output dimension. For\n",
    "example, to locate the center of an object on an image, you need to predict 2D coordi‐\n",
    "nates, so you need two output neurons. If you also want to place a bounding box\n",
    "around the object, then you need two more numbers: the width and the height of the\n",
    "object. So you end up with 4 output neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">In general, when building an MLP for regression, you do not want to use any activa‐\n",
    "tion function for the output neurons, so they are free to output any range of values.\n",
    "However, if you want to guarantee that the output will always be positive, then you\n",
    "can use the ReLU activation function, or the softplus activation function in the output\n",
    "layer. Finally, if you want to guarantee that the predictions will fall within a given\n",
    "range of values, then you can use the logistic function or the hyperbolic tangent, and\n",
    "scale the labels to the appropriate range: 0 to 1 for the logistic function, or –1 to 1 for\n",
    "the hyperbolic tangent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The Huber loss is quadratic when the error is smaller than a threshold δ (typically 1), but linear when the error is larger than δ. This\n",
    "makes it less sensitive to outliers than the mean squared error, and\n",
    "it is often more precise and converges faster than the mean absolute error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<figcaption><h4>Typical Regression MLP Architecture</h4></figcaption>\n",
    "<img src = \"img/10_09.png\">\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification MLPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLPs can also be used for classification tasks. For a binary classification problem,\n",
    "you just need a single output neuron using the logistic activation function: the output\n",
    "will be a number between 0 and 1, which you can interpret as the estimated probability of the positive class. Morever, MLPs can be used to predict multiple classes too. In this case, you would need two output neurons, both using the logistic activation function.<br>\n",
    "If each instance can belong only to a single class, out of 3 or more possible classes\n",
    "(e.g., classes 0 through 9 for digit image classification), then you need to have one\n",
    "output neuron per class, and you should use the softmax activation function for the\n",
    "whole output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<figcaption><h4>Typical Classification MLP Architecture</h4></figcaption>\n",
    "<img src = \"img/10_10.png\">\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A great link **https://playground.tensorflow.org/**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing MLPs with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras was developed by François Chollet as part of a\n",
    "research project and released as an open source project in March 2015. To perform the heavy computations required by neural networks, keras-team relies on a\n",
    "computation backend. At the present, you can choose from three popular open\n",
    "source deep learning libraries: TensorFlow, Microsoft Cognitive Toolkit (CNTK) or\n",
    "Theano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building an Image Classifier Using the Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use MNIST's *Fashion* dataset for building a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since MNIST provides label for each class, we need a way to infer what value does the label corressponds to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "\"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first see how well the linear classifier performs on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lin = X_train_full.reshape((60000,784))/255.0\n",
    "X_test_lin = X_test.reshape((10000,784))/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lin.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "lr.fit(X_train_lin, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8443"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test_lin, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, a simple linear model gives 84% of accuracy. We can, of course, improve this but let's stick with this for now! Now, let's build a classifier using the Sequential API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MLP can be implemented using two ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "keras.layers.Flatten(input_shape=[28, 28]),\n",
    "keras.layers.Dense(300, activation=\"relu\"),\n",
    "keras.layers.Dense(100, activation=\"relu\"),\n",
    "keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How is it done?<br>\n",
    "* The first line creates a Sequential model. This is the simplest kind of Keras\n",
    "model, for neural networks that are just composed of a single stack of layers, con‐\n",
    "nected sequentially. This is called the sequential API.\n",
    "* Next, we build the first layer and add it to the model. It is a Flatten layer whose\n",
    "role is simply to convert each input image into a 1D array: if it receives input data\n",
    "X, it computes X.reshape(-1, 1). This layer does not have any parameters, it is\n",
    "just there to do some simple preprocessing. Since it is the first layer in the model,\n",
    "you should specify the input_shape: this does not include the batch size, only the\n",
    "shape of the instances. Alternatively, you could add a `keras.layers.InputLayer`\n",
    "as the first layer, setting `shape=[28,28]`.\n",
    "* Next we add a Dense hidden layer with 300 neurons. It will use the ReLU activation function. Each Dense layer manages its own weight matrix, containing all the\n",
    "connection weights between the neurons and their inputs. It also manages a vector of bias terms, one per neuron.\n",
    "* Next we add a second Dense hidden layer with 100 neurons, also using the ReLU\n",
    "activation function.\n",
    "* Finally, we add a Dense output layer with 10 neurons (one per class), using the\n",
    "softmax activation function (because the classes are exclusive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model’s `summary()` method displays all the model’s layers, including each layer’s\n",
    "name (which is automatically generated unless you set it when creating the layer), its\n",
    "output shape (None means the batch size can be anything), and its number of parame‐\n",
    "ters. The summary ends with the total number of parameters, including trainable and\n",
    "non-trainable parameters. You can also generate an image of your model using `keras.utils.plot_model()`. Furthermore, ll the parameters of a layer can be accessed using its `get_weights()` and\n",
    "`set_weights() `method. For a Dense layer, this includes both the connection weights\n",
    "and the bias terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x2187468b310>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2186bf52f10>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x21874298250>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x218746914c0>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06480089, -0.07192267,  0.06306447, ...,  0.00244816,\n",
       "         0.07386684, -0.06686679],\n",
       "       [ 0.05389889,  0.06494448,  0.00671749, ...,  0.05636494,\n",
       "        -0.06254327,  0.06099726],\n",
       "       [ 0.02433742, -0.05609208,  0.02134802, ...,  0.03174756,\n",
       "         0.0121516 , -0.04439304],\n",
       "       ...,\n",
       "       [-0.07298393,  0.02424685, -0.0043864 , ..., -0.02537306,\n",
       "        -0.02095705, -0.01141737],\n",
       "       [ 0.02961305,  0.07109299,  0.05594206, ...,  0.00472962,\n",
       "         0.05424826,  0.03382988],\n",
       "       [ 0.01390176, -0.04097348, -0.06613321, ..., -0.05188762,\n",
       "         0.01220762,  0.03269567]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the Dense layer initialized the connection weights randomly (which is\n",
    "needed to break symmetry), and the biases were just initialized to zeros, which is fine. If you ever want to use a different initialization method,\n",
    "you can set `kernel_initializer` (kernel is another name for the matrix of connection weights) or `bias_initializer` when creating the layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784, 300), (300,))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape, biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The shape of the weight matrix depends on the number of inputs.\n",
    "This is why it is recommended to specify the input_shape when\n",
    "creating the first layer in a Sequential model. However, if you do\n",
    "not specify the input shape, it’s okay: Keras will simply wait until it\n",
    "knows the input shape before it actually builds the model. This will\n",
    "happen either when you feed it actual data (e.g., during training),\n",
    "or when you call its `build()` method. Until the model is really\n",
    "built, the layers will not have any weights, and you will not be able\n",
    "to do certain things (such as print the model summary or save the\n",
    "model), so **if you know the input shape when creating the model, it\n",
    "is best to specify it**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a model is created, you must call its `compile()` method to specify the loss function and the optimizer to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "optimizer=\"sgd\",\n",
    "metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `loss=\"sparse_categorical_crossentropy\"` is equivalent to\n",
    "`loss=keras.losses.sparse_categorical_crossentropy`. Similarly, `optimizer=\"sgd\"` is equivalent to `optimizer=keras.optimizers.SGD()` and `metrics=[\"accuracy\"]` is equivalent to\n",
    "`metrics=[keras.metrics.sparse_categorical_accuracy]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use the `sparse_categorical_crossentropy` loss because we have sparse labels (i.e., for each instance there is just a target\n",
    "class index, from 0 to 9 in this case), and the classes are exclusive. If instead we had\n",
    "one target probability per class for each instance (such as one-hot vectors, e.g. [0.,\n",
    "0., 0., 1., 0., 0., 0., 0., 0., 0.] to represent class 3), then we would need\n",
    "to use the `categorical_crossentropy` loss instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the model is ready to be trained. For this we simply need to call its `fit()`\n",
    "method. We pass it the input features `(X_train)` and the target classes `(y_train)`, as\n",
    "well as the number of epochs to train. Default value of numbers of epoch is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 13s 4ms/step - loss: 0.7209 - accuracy: 0.7648 - val_loss: 0.5297 - val_accuracy: 0.8196\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4870 - accuracy: 0.8301 - val_loss: 0.4538 - val_accuracy: 0.8448\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4425 - accuracy: 0.8451 - val_loss: 0.4136 - val_accuracy: 0.8594\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4151 - accuracy: 0.8557 - val_loss: 0.4095 - val_accuracy: 0.8608\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3950 - accuracy: 0.8618 - val_loss: 0.3811 - val_accuracy: 0.8696\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3796 - accuracy: 0.8672 - val_loss: 0.3799 - val_accuracy: 0.8668\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3650 - accuracy: 0.8715 - val_loss: 0.3595 - val_accuracy: 0.8738\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.3529 - accuracy: 0.8763 - val_loss: 0.3852 - val_accuracy: 0.8670\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3443 - accuracy: 0.8777 - val_loss: 0.3428 - val_accuracy: 0.8778\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3336 - accuracy: 0.8820 - val_loss: 0.3428 - val_accuracy: 0.8800\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.3243 - accuracy: 0.8860 - val_loss: 0.3380 - val_accuracy: 0.8794\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3176 - accuracy: 0.8876 - val_loss: 0.3441 - val_accuracy: 0.8772\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3103 - accuracy: 0.8899 - val_loss: 0.3242 - val_accuracy: 0.8812\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3022 - accuracy: 0.8926 - val_loss: 0.3478 - val_accuracy: 0.8762\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2963 - accuracy: 0.8947 - val_loss: 0.3213 - val_accuracy: 0.8856\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.2894 - accuracy: 0.8967 - val_loss: 0.3193 - val_accuracy: 0.8854\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2839 - accuracy: 0.8994 - val_loss: 0.3078 - val_accuracy: 0.8884\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2782 - accuracy: 0.9010 - val_loss: 0.3229 - val_accuracy: 0.8876\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2726 - accuracy: 0.9023 - val_loss: 0.3062 - val_accuracy: 0.8896\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2679 - accuracy: 0.9034 - val_loss: 0.3038 - val_accuracy: 0.8870\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2629 - accuracy: 0.9052 - val_loss: 0.3004 - val_accuracy: 0.8924\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2585 - accuracy: 0.9076 - val_loss: 0.2985 - val_accuracy: 0.8906\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2532 - accuracy: 0.9088 - val_loss: 0.2972 - val_accuracy: 0.8962\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2491 - accuracy: 0.9097 - val_loss: 0.3187 - val_accuracy: 0.8844\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2452 - accuracy: 0.9117 - val_loss: 0.2991 - val_accuracy: 0.8910\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2394 - accuracy: 0.9147 - val_loss: 0.3101 - val_accuracy: 0.8858\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2360 - accuracy: 0.9157 - val_loss: 0.2923 - val_accuracy: 0.8928\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2330 - accuracy: 0.9171 - val_loss: 0.3037 - val_accuracy: 0.8936\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2282 - accuracy: 0.9174 - val_loss: 0.2897 - val_accuracy: 0.8938\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2255 - accuracy: 0.9193 - val_loss: 0.2992 - val_accuracy: 0.8928\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Instead of passing a validation set using the `validation_data`\n",
    "argument, you could instead set `validation_split` to the ratio of\n",
    "the training set that you want Keras to use for validation (e.g., 0.1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the training set was very skewed, with some classes being overrepresented and others underrepresented, it would be useful to set the `class_weight` argument when\n",
    "calling the `fit()` method, giving a larger weight to underrepresented classes, and a\n",
    "lower weight to overrepresented classes. These weights would be used by Keras when\n",
    "computing the loss. If you need per-instance weights instead, you can set the `sample_weight` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit()` method returns a History object containing the training parameters (`history.params`), the list of epochs it went through (`history.epoch`), and most importantly a dictionary (`history.history`) containing the loss and extra metrics it\n",
    "measured at the end of each epoch on the training set and on the validation set.<br>\n",
    "Let's plot these values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(history.history).plot(figsize=(10, 7))\n",
    "plt.grid(True)\n",
    "plt.ylim([0,1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that both the training and validation accuracy steadily increase during\n",
    "training, while the training and validation loss decrease. Moreover, the validation curves are quite close to the training curves this shows that the model is not overfitting. Since the validation loss is still going down, it means that the model has yet not converged abd you can keep training the model for more epochs. **It’s as simple as calling the `fit()` method again, since Keras just continues training where it left off.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 4ms/step - loss: 59.5654 - accuracy: 0.8561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[59.565399169921875, 0.8561000227928162]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm! 85.6% accuracy. Not that good from the simple `LogisticRegressor`. Also note that the accuracy on validation set was 89.3%. Generally, the score on test set is lower than that on validation test, for obvious reasons!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try tuning the hyperparameters. But let's assume that we are satisfied with the model. Time to evaluate our model. On second thoughts, let's train for 10 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 11s 5ms/step - loss: 0.2215 - accuracy: 0.9222 - val_loss: 0.2834 - val_accuracy: 0.8958\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.2182 - accuracy: 0.9215 - val_loss: 0.3307 - val_accuracy: 0.8794\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2145 - accuracy: 0.9228 - val_loss: 0.2890 - val_accuracy: 0.8940\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2103 - accuracy: 0.9249 - val_loss: 0.2917 - val_accuracy: 0.8932\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2073 - accuracy: 0.9258 - val_loss: 0.2888 - val_accuracy: 0.8944\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2035 - accuracy: 0.9264 - val_loss: 0.2992 - val_accuracy: 0.8920\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2005 - accuracy: 0.9284 - val_loss: 0.2933 - val_accuracy: 0.8946\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.1969 - accuracy: 0.9295 - val_loss: 0.2937 - val_accuracy: 0.8958\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.1949 - accuracy: 0.9302 - val_loss: 0.2848 - val_accuracy: 0.8968\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.1906 - accuracy: 0.9323 - val_loss: 0.3086 - val_accuracy: 0.8862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21874e16a30>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAGfCAYAAAB7g1e6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA7XklEQVR4nO3deXxV9YH///fnLlkgJOxJCIuhLoCEiAY3LKbAuIzWZbQFax2L29exdaHzmFLtMnaccVqd/h5tf25DW7V8a6uO1a/WWv2WJSJuBRQFRSkiS9gDhCRAkrt8vn/cJffe3CQ3nBvuveH11PvIOZ/zOZ/zSU64553POfccY60VAAAAjo4r0x0AAADIZYQpAAAABwhTAAAADhCmAAAAHCBMAQAAOECYAgAAcKDHMGWMedwYs8cYs66L5cYY8wtjzEZjzIfGmNPT300AAIDslMrI1JOSLupm+cWSTgq/bpH0qPNuAQAA5IYew5S1drmk/d1UuVzSIhvyjqTBxpjydHUQAAAgm3nS0EaFpG0x8/Xhsp2JFY0xtyg0eqXCwsIzxowZk4bNdy8YDMrl4tKwXMX+y33sw9zHPsxt7L/02LBhQ4O1dkSyZekIUyZJWdJn1FhrF0paKEk1NTV21apVadh89+rq6lRbW9vn20HfYP/lPvZh7mMf5jb2X3oYY7Z0tSwdUbVeUuwQ02hJO9LQLgAAQNZLR5h6SdI/hj/Vd7akg9baTqf4AAAA+qMeT/MZY34vqVbScGNMvaR/leSVJGvtY5JekfT3kjZKOixpXl91FgAAINv0GKastdf0sNxK+mbaegQAAJBDuLwfAADAAcIUAACAA4QpAAAABwhTAAAADhCmAAAAHCBMAQAAOECYAgAAcIAwBQAA4ABhCgAAwAHCFAAAgAOEKQAAAAcIUwAAAA4QpgAAABwgTAEAADhAmAIAAHCAMAUAAOAAYQoAAMABwhQAAIADhCkAAAAHPJnuAAAAyBBrJRuUgv6YVyD88ks2EFMW+9WfXeudfKF05s0Z+zESpgCgv4o7UMYerMKvuANXIGZZfL2Sxo+lzd5QW5GXwm1HttHpZbuYTly/mzqdymwPbaSw3cRyJdSXTf41aVmwm/rBjn0Qt6y77cQuUy+2Y5Os19HWOW2t0kpP8pBiA33/e9gbLk/oZdzh6SRfo8si5W6p/VBGu02YAvoLm/im3MNBI+6NuLv6tod2Yss7H2BLGtdJn7u6OYCoi/JUDj6243tP+WDTizZSWtf2Opx0G2qShp9g57/aU6kXOaA7NFWS1qSlqfQyrq5fMpIx3dcxiqnrCtWPrBe7flyZuq/f1TJXd/WTbSd2WS+2E7cs1Nd9u3ZpVMWYmKDiSggjMV/jQkxsaEl1PU/oe40LRYnhJ1koCq+XowhTOLZiD76RA4INht78bTB0MIgpy2/dKx3Y3MPBqou/uruc7+5glMq6SQ5snQ6Iqa7b1V/ZPYeUTvVlM7pru5K1B+K+kHgwih58Yg84roR6ruQHHU9BwgEnSb3Y9tNdL6a/H3y4TtWnTe04eHcKJQll6qlOdyHHdNNGbB2T6b2dMzbU1WlUbW2mu9Gv9d8wtecT6fdzdNaRVunDgT38BdCR4Lte3sX6Pf2lkOyvjR77kmxayetGDqjBQPhAGxNQomEl0HEQjiuL1AsmKYsNOsnaCx/Ae9teLw/450jSO45+E45Op6Hm7g6A3Rw4PfmSa0DCQcsdP2/cHfu300HEJJSbLsoT65se2kk4KPW43YS6vejnmg8+1GmnTU3yb6Wrr4pvI6V1Yr+q63+PvWqjF+vm+F/VPTlQ75HGn5/pbgBZq/+GKW+hNPpMNe3epcKRI5MM10f+mlcXw/kJpxbilqsjNPRYN7JcPSxPtr56qBuMOZi5wgdlV3g4ObHMHXOAiy1zxUx748t6bC9yEE1sJ1LPJClzJbSZbN2O1yd/26gJEybFDzsnDkMnnlvvKrQkrdvFyAHSpnGrpMovZrobANBn+m+YGjJOuuqXWl9Xp1KGN3PWrpY6TZham+luAADQJf4EBwAAcIAwBQAA4ABhCgAAwAHCFAAAgAOEKQAAAAcIUwAAAA7031sjAACQRWz00UxWCgZD88Fg0nkbKY8sC8bcZzBSN7osSV11LPNs3ab2+nq5S0rkKiqS4e7xaddvw1T71q3a9k+3aXB+nnb85S/ylpbJU14mb1mZPKWl8paX80uVxay1CjY1yb13r9q3bZOMCe2ryMsVujO2cSWWKVQv8hws4wrfpLqjrFM7kbJ+IvqGHPvmHPtmHHnzTVqeUCfxzToQ6L5OeFnsdN66dTqUlye5PTIet4zbHZ2W2y3j8XaUezzh5W4Zr1fGHVPOzVRTYgMB2UBA8vlC036/rN8v+f2heZ9fCvjD5QFZvy+0XxPnfX7ZQGi9go8/VuO+/XH71gYDoX0cfuKB7XI64fci0Mv6wdCTFrquH/v7Hoz2Ke53vKt/EzbJusmCTUy7ofluQlA3y6I3fT7Ghkn67P77QzNut9wlJR2vwYPDX0vkip0vGRyaHlxCCEtBvw1TCgaVP368Dm3YoEPL35C/oaHTL7JrwAB5ysvlLS2VpywctMpKw19D865Bg/gFSiNrrQKNjfLv2SP/nr3y7w2/9uzpmA6/bFubhkv67Fh1LjFgSR2hzOUKP+UkNqjFBLNomWSMK6ZMMuphneibbvhAk/Kbf3g6EIgrzzZDJG1NR0PGRMOWiYSu6Fe3jNsTKveEw1psudst4/UkLZcnHOhSKY8EQLcn3J5bxuUKhZBw8AgFknBg8YUDjN8nhcttIBJuOua7Xi+yLDQfO524LDLfFwfsEkk7nTYS+Z13uULB2OXq+MMnYVouE/p3FDvtdsfXd0WesNBF/djt9FjfRJ8SEVcv8u85XC/07zdmWeRJDol1k7UTrRtuJ/oUiG7qGhPqX3Q+yTYT20ms63Jp3YcfauLYcQocPKhAY6MCBxuj0749u9W2YYMCjY0KHj7c9f6LDWHRwBUKYe7Bg0NBLLpscEf5wIHHxTG034apvBNO0Oj//xfaWFen2tpaWZ9P/j175Nu9W76dO+XftVu+3bvk37lLvt271bZihfx793Z6IzIDBshbViZvWak8pWXylpeFvpaVylNWLm9ZqVzFxcfFL0t3bCCgwP790SDkSwxHkeDU0CD5fJ3WdxUVyTNihDwjR6rwtNNC0yNG6G+7dmnCxInRR/d0DGcrOuQdChIxw+c2GF8WXU8dj+vptF7ssHmS9SLblQ2PzHS9nrUxfUy2XuR7iazTxYFAblfy8sTpmDfpTtMud891Ok274t6UjTuxTVfHwSBSJ7Z+wvR7772nqVOmdASOQKBz+OhUHugIIUnK4wJHYnnsupFyv1/BI62dAkl0tCZxOjKqEy53JCYAyuOJBsHEeXk9HYHQ7ZbJz5NrwIDOyzyREOkJt9ER+qIBLzLa5wkHyMT1ovU80VfS9byhEcF3Vq3SOeec0xF2YvZ/9Pegu3DUz0Z/c02by6XBKTwJxLa3K9DUFA5cB8OB62DMfGNo/mAohLVu+FTBxoOphbDYABaZD4+GeaJhrGM0LNdCWL8NU4mM1ytvRYW8FRVd1rE+XygI7Not/66doa+7d8m3c5d8u3ep7a23QoEr4a9/M2BAeHSrVN6y8tDXSPAqK5O3tFSukpKc+sWIsH6//Pv2dYwc7eliJGnfPikQ6LS+u6REnpGhYJRfWRmdjgSnyLSrsDDp9tfW1aX0JoDs5Wts1ICamkx346hFRv26CmIKBOJDUVwgcefkv/tEwc2bu33vRP9g8vLkGT5cnuHDe7WebW/vCF+R0a/GmOmYct/uUAgLNB6U7S6EeTzx4SvhlGRkOnJq0lta2ut+p9NxE6ZSYbxeeUeNknfUKElTk9axPp/8DQ3y7dol/65d8cFr1y4d6ipwFRZ2ezrRU1oq9+DBx+yNN9jerkBkFClZOAqHpsD+/UlPG7iHDYsGofxTTokPSSNGyDNipDwjhsuVn39Mvh+grxhjwqf23FJeXqa7A2Qdk5cXfe/vjWB7u4JJAleyIObbtUutn36qwMHkIWzw3Dkqv/feNH1HvUeY6iXj9cpbXi5veXmXdazfHwpcO3fKv3t3KHiFTyf6d+3SoXfekX/Pns6Bq6AgFLhir+MqD18wHw5ePQWu4JEjyU+vJYSlQGNj55VdLnmGDZNn5Eh5y8pUWFXVMYIUG5aGDZPxeo/2RwgAgFx5eXIdZQgLNDaGglg4dHlKy/qol6khTPUB4/GEr7PqeudGT5/t7Hw60b9zlw799a+hwJVw6szk50dPJ3rLSmWDNi4sBZubO2/M6w0N3Y4YIe+4sSqsOSNuFMkbPt3mHjo09Nc3AABZypWXJ9fIkdLIkZnuShRhKkOMxyNvaam8paVKfrVQ6KJuf0ND59OJ4eB1aOVKGZc7dKrtxBM18Jxz4q5D8owMjSq5S0r4WDkAAH2EMJXFjNvdEbiqM90bAACQDMMVAAAADhCmAAAAHCBMAQAAOECYAgAAcIAwBQAA4ABhCgAAwAHCFAAAgAOEKQAAAAcIUwAAAA4QpgAAABwgTAEAADhAmAIAAHCAMAUAAOAAYQoAAMABwhQAAIADhCkAAAAHCFMAAAAOEKYAAAAcIEwBAAA4QJgCAABwgDAFAADgAGEKAADAAcIUAACAA4QpAAAABwhTAAAADqQUpowxFxljPjXGbDTGfDfJ8hJjzB+NMR8YYz4yxsxLf1cBAACyT49hyhjjlvSwpIslTZJ0jTFmUkK1b0r62FpbLalW0k+NMXlp7isAAEDWSWVk6kxJG621m6y17ZKelnR5Qh0raZAxxkgqkrRfkj+tPQUAAMhCnhTqVEjaFjNfL+mshDoPSXpJ0g5JgyTNsdYGExsyxtwi6RZJKi0tVV1d3VF0uXdaWlqOyXbQN9h/uY99mPvYh7mN/df3UglTJkmZTZi/UNIaSTMlfUHSX4wxb1hrm+JWsnahpIWSVFNTY2tra3vb316rq6vTsdgO+gb7L/exD3Mf+zC3sf/6Xiqn+eoljYmZH63QCFSseZKetyEbJX0uaUJ6uggAAJC9UglTKyWdZIypDF9UPlehU3qxtkqaJUnGmFJJp0jalM6OAgAAZKMeT/NZa/3GmG9Jek2SW9Lj1tqPjDG3hpc/Juk+SU8aY9YqdFpwgbW2oQ/7DQAAkBVSuWZK1tpXJL2SUPZYzPQOSRekt2sAAADZjzugAwAAOECYAgAAcIAwBQAA4ABhCgAAwAHCFAAAgAOEKQAAAAcIUwAAAA4QpgAAABwgTAEAADhAmAIAAHCAMAUAAOAAYQoAAMABwhQAAIADhCkAAAAHCFMAAAAOEKYAAAAcIEwBAAA4QJgCAABwgDAFAADgAGEKAADAAcIUAACAA4QpAAAABwhTAAAADhCmAAAAHCBMAQAAOECYAgAAcIAwBQAA4ABhCgAAwAHCFAAAgAOEKQAAAAcIUwAAAA4QpgAAABwgTAEAADhAmAIAAHCAMAUAAOAAYQoAAMABwhQAAIADhCkAAAAHCFMAAAAOEKYAAAAcIEwBAAA4QJgCAABwgDAFAADgAGEKAADAAcIUAACAA4QpAAAABwhTAAAADhCmAAAAHCBMAQAAOECYAgAAcIAwBQAA4ABhCgAAwAHCFAAAgAOEKQAAAAcIUwAAAA4QpgAAABwgTAEAADhAmAIAAHCAMAUAAOAAYQoAAMABwhQAAIADhCkAAAAHCFMAAAAOEKYAAAAcIEwBAAA4QJgCAABwgDAFAADgQEphyhhzkTHmU2PMRmPMd7uoU2uMWWOM+cgY83p6uwkAAJCdPD1VMMa4JT0s6e8k1UtaaYx5yVr7cUydwZIekXSRtXarMWZkH/UXAAAgq6QyMnWmpI3W2k3W2nZJT0u6PKHO1yQ9b63dKknW2j3p7SYAAEB26nFkSlKFpG0x8/WSzkqoc7IkrzGmTtIgST+31i5KbMgYc4ukWySptLRUdXV1R9Hl3mlpaTkm20HfYP/lPvZh7mMf5jb2X99LJUyZJGU2STtnSJolqVDS28aYd6y1G+JWsnahpIWSVFNTY2tra3vd4d6qq6vTsdgO+gb7L/exD3Mf+zC3sf/6Xiphql7SmJj50ZJ2JKnTYK09JOmQMWa5pGpJGwQAANCPpXLN1EpJJxljKo0xeZLmSnopoc6Lkr5ojPEYYwYodBpwfXq7CgAAkH16HJmy1vqNMd+S9Jokt6THrbUfGWNuDS9/zFq73hjzqqQPJQUl/cpau64vOw4AAJANUjnNJ2vtK5JeSSh7LGH+QUkPpq9rAAAA2Y87oAMAADhAmAIAAHCAMAUAAOAAYQoAAMABwhQAAIADhCkAAAAHCFMAAAAOEKYAAAAcIEwBAAA4QJgCAABwgDAFAADgAGEKAADAAcIUAACAA4QpAAAABwhTAAAADhCmAAAAHCBMAQAAOECYAgAAcIAwBQAA4ABhCgAAwAHCFAAAgAOEKQAAAAcIUwAAAA4QpgAAABwgTAEAADhAmAIAAHCAMAUAAOAAYQoAAMABwhQAAIADhCkAAAAHCFMAAAAOEKYAAAAcIEwBAAA4QJgCAABwgDAFAADgAGEKAADAAcIUAACAA4QpAAAABwhTAAAADhCmAAAAHCBMAQAAOECYAgAAcIAwBQAA4ABhCgAAwAHCFAAAgAOEKQAAAAcIUwAAAA4QpgAAABwgTAEAADhAmAIAAHCAMAUAAOAAYQoAAMABwhQAAIADhCkAAAAHCFMAAAAOEKYAAAAcIEwBAAA4QJgCAABwgDAFAADgAGEKAADAAcIUAACAA4QpAAAABwhTAAAADhCmAAAAHCBMAQAAOECYAgAAcIAwBQAA4ABhCgAAwIGUwpQx5iJjzKfGmI3GmO92U2+aMSZgjLk6fV0EAADIXj2GKWOMW9LDki6WNEnSNcaYSV3U+4mk19LdSQAAgGyVysjUmZI2Wms3WWvbJT0t6fIk9W6X9AdJe9LYPwAAgKzmSaFOhaRtMfP1ks6KrWCMqZB0paSZkqZ11ZAx5hZJt0hSaWmp6urqetnd3mtpaTkm20HfYP/lPvZh7mMf5jb2X99LJUyZJGU2Yf5nkhZYawPGJKseXsnahZIWSlJNTY2tra1NrZcO1NXV6VhsB32D/Zf72Ie5j32Y29h/fS+VMFUvaUzM/GhJOxLq1Eh6Ohykhkv6e2OM31r7f9LRSQAAgGyVSphaKekkY0ylpO2S5kr6WmwFa21lZNoY86SklwlSAADgeNBjmLLW+o0x31LoU3puSY9baz8yxtwaXv5YH/cRAAAga6UyMiVr7SuSXkkoSxqirLXfcN4tAACA3MAd0AEAABwgTAEAADhAmAIAAHCAMAUAAOAAYQoAAMABwhQAAIADhCkAAAAHCFMAAAAOEKYAAAAcIEwBAAA4QJgCAABwgDAFAADgAGEKAADAAcIUAACAA4QpAAAABwhTAAAADhCmAAAAHCBMAQAAOECYAgAAcMCT6Q6g9xpbG7Vs2zLVbauT1+3V9FHTNb1iukYOGJnprgEAcNwhTOWIXYd2aenWpVq6dalW7V6lgA2obGCZAsGAXtv8miTp5CEna3rFdJ036jxNHTlVXrc3w70GAKD/I0xlsS1NW7R4y2It3bpUHzZ8KEmqLKnUDZNv0KxxszRp6CRJ0oYDG/Tmjjf15vY39b8//t96Yt0TGuAZoDPLz9R5o87T9IrpGj1odCa/FQAA+i3CVBax1urTA59q8ZbFWrJ1iTY2bpQkTRo2SXdMvUOzxs7S+MHjO613ytBTdMrQU3TD5Bt0yHdI7+58V29uf1Mrtq9Q3bY6SdIJxSfovIpQsKoprVGBp+AYfmcAAPRfhKkMC9qgPtj7gZZsWaLFWxdre8t2uYxLU0dO1YJpCzRz7EyNKhqVcnsDvQM1c+xMzRw7U9ZabW7aHApWO1bofzb8j367/rfKd+erprRG0ytC11pVFlfKGNOH3yUAAP0XYSoDfEGfVu5cqSVbl2jptqVqONIgj8ujs8vP1s1VN6t2TK2GFQ5zvB1jjCpLKlVZUqmvT/q6Wv2tWr17tVZsX6EV21fogZUPSCulUQNHha61qjhPZ5WfpYHegWn4LgEAOD4Qpo6RI/4jemv7W1qydYnq6uvU3N6sQk+hzqs4T7PHztYXR39Rg/IG9WkfCjwF0dGoBVqg+uZ6vbXjLa3YvkJ/2vQn/c+G/5HHeDS1dKqmjwqFq5OHnMyoFQAA3SBM9aGm9ia9vu11Ld26VCu2r1BroFXFecX60pgvafbY2Tpn1DkZvXZp9KDR+uopX9VXT/mqfAGf1uxdEx21+tl7P9PP3vuZRhSO0LmjztV5FefpnFHnqCS/JGP9BQAgGxGm0qzhSIOWbVumJVuW6N2d78pv/RpROEKXn3i5Zo+brTNKz5DXlX23LPC6vZpWNk3TyqZp/hnztefwHr25/U29ueNNLd22VC9+9qJcxqXJwyfrvIrzdN6o8zRp2CS5Xe5Mdx0AcBzyBXza2rxVmw5u0sgBI1U9ojpjfSFMpcH2lu1asmWJlmxdovf3vC8rqzGDxui6Sddp1rhZqhpeJZfJrZvNjxwwUleedKWuPOlK+YN+rWtYF739wqNrHtUjax7R4PzBOmfUOTqv4jydO+pcDS8cnuluAwD6mcO+w/q86XNtatykzw9+rk0HN+mzxs9U31wvv/VLkq488UrCVK6x1mrTwU3RWxis379eUuimmf9U/U+aNW6WThp8Ur+51sjj8ui0kafptJGn6ZunfVMHWg/orR1vRUeu/vz5nyVJE4dOjN5+YcqIKVk5AgcAyE4HWg9o08FNoVdMcNp5aGe0jsd4NKZ4jL4w+Av6u3F/p8qSSo0fPF6VxZUZ7DlhKmXWWq1rWKclW0MjUJubNkuSqkdU65/P+GfNGjtLY4rHZLaTx8iQgiG6ZPwlumT8JQraoD7Z/0n0vlaPr3tcv1z7SxV5i3R2+dmhC95HTVd5UXmmuw0AyDBrrXYf3q1NjaHQ9NnBz6LB6UDbgWi9AneBKksqNXXkVF1VcpXGDx6v8SXjNXbQ2Kx8ugdhqhv+oF/v73k/OgK1+/BuuY1b08qm6esTv64vjf3Scf88PJdxadKwSZo0bJJunnKzmtub9e7Od6MXsi/euliS9IWSL0Q/SXhG6RnKd+dnuOdActZaHfYf1sG2g6FX+8HodFN7U0d5eNlh32EVeApU4C4IffUUaIBnQFxZoadQhZ7CaFlkutBTGJr3FkbL8935XIuInOcP+rWteZs2HQyPMIXD0+cHP9dh/+FovZL8Eo0vGa+ZY2eGRplKxmv84PEqH1ieU5fHEKYStAXa9O7Od7V4y2It27ZMjW2Nynfn69xR5+qO0+/Q+aPP5xNt3RiUN0izx83W7HGzZa3VZ42f6c0doVGr33/yey36eJEKPYWaVjYtevuFscVjM91t9ENBG1Rze7Oa2priAlGX4Shc3tTWFL0OI5kCd4GK84pVnF+skvwSDS8crvZguw77D2t/634d8R9Rq79VRwJHdMR/RP5g1211Jd+dHxe8ugxiMYEsWWiLC3YJ6+fSgQrZq9Xfqs1Nm/VZ42dxwWlL85a43/2RA0ZqfMl4XXHiFdHANL5kvIYWDO0Xl8QQpiQd8h3SG9vf0JItS7S8frkO+w+ryFukGaNnaPa42Zo+aroGeAdkups5xxijE4ecqBOHnKjrT71eh32HtWr3quio1fL65ZKkMYPGRIPVtLJp/KwRxxf0RQNRU1tTp0AUmU9c1tzeLCvbZbsDvQNVkleikvwSFecX66QBJ6kkPzQfWx6ZLskvUXFeca9vZ+IL+tTmb1NroFVHfEd0JBAKW63+Vh3xd56PBLHY+UjZIf8h7Wvd16muk8AWHR3rIpwVeAq0Y/8OvfvXdyVJVlbW2rjp2J9zZD62XrK6idPROoltWnVqr6s2Iv91rNq5vcjy2PY8Lo+K8opUnFesIm+RBuUNir6SzRd6CvtFAOiNg20Ho9cwRUaZNh3cpB0tO6I/W5dxacygMaosqdT5Y84PhaaS8aosqVRRXlGGv4O+ddyGqQOtB1S3rU5Lti7R2zveVnuwXUMLhuriyos1e9xsnVl2pvLceZnuZr8ywDtAM0bP0IzRMyRJW5u2asX2FXpzx5t68bMX9fSnT8vr8ur00tP1xYovavqo6XFvxlLoDTNgA/IH/dGvvqAvbj76sh3TgWAgWuYL+uLm49ZJaMcX9HVqN2ADKW0zpT5Zv1zGJY/LI4/xhL66PPK6vNHp2PLYl9fl7XJZZL24dhKWddpOL5YlLk9llKPV39ppJChpOEooP+Q71GWbRkaD8gbFBaAxxWPiAlCycFScX3zMPiDhdXnlzfOqSEVSYd9swxf0RUNX7KhY3LzviFoDrfFBzt9RFqnf4mtRw5GGuPV9fp88G0OHCyOj0P8mGihM5L+YgBGZNzJHvV5sPUmd2osuT9JepF7sep3aCfenPdCuzU2b1dLeoub25m5HJqXQRdBFeUWdwlay4FWcVxytO8gbLs8rkseVfYdfa632HtkbP8oUDk/7WvdF6+W58nRCyQmqGl6ly79wuSoHh07PjSsed9xewmESD1bHSk1NjV21alWfb6eurk61tbWSpF2Hdmnp1qVasnWJVu9erYANqHxguWaNnaVZY2dp6sipXKuQIW2BNr23+73oJwQjD3kuMAXyeDxxYeRYchmX3MYdFyBi5z0uj9zGHRcsEpfHBpDEtlzGpaANdhns/EG/fNYXPx/0Ja0XCYqxZd2NzKT755Qs2HldXh06ckitalVroLXL9T3GEz1tljgSlBiIItPF+cUalDeI01XHQOz7aH9nrVVroFXN7c1qaW9RU3uTWnwtcdPN7c3RV7L57v4AiCj0FMaFq6K8IhV7Y4JXOHwlmy/OK+7V6Fji/gsEA9resj3pJ+dafC3ReoO8g6JBKfY1qmjUcXmsNMasttbWJF3W38PUs395Vs1lzVqydYnWNqyVJI0vGa9ZY2dp9rjZmjh04nE3XJsLdh3apTe3v6ml65Zq7OixPYcUlztuRCV2Ptk6bleoLa/xxs0ntpvrB+rI6Fe3Qay75QkBL255kvAXXR6zrGF3gyacMKHbcDTAM4B/h1nseApT6RAIBqIhK1nYampvio6CxS6PTDe1N/V46tZt3KEQFjP61dXI2MZPN2rg6IHR8LTl4Ba1B9ujbQ0vHB49HRe5nukLJV/Q8MLh/LuM0V2Yyr5xxjT5dP+n+u4b3w2NcOyQTh12qu48/U7NHDtT40vGZ7p76EHZwDJddfJVGrZjmGrPrM10d3KW2+WWW+6MDr3X1dWptqY2Y9sHjjW3yx39Q+FoWGvVFmjrFLyafc3REbNoQPN1zNe31EeXx44wSZLZZ1RRVKHxg8dr+qjp0fBUWVLJh6rSoN+GqbKBZRpaMFRXDblK/2vm/+I+RwCAnGCMiX4C82ifLBEIBnTIf0gt7S1a/vZyXfGlKzL6LNj+LrfPYXSjJL9Ev77w16otriVIAQCOK26XW8V5xRpVNEpl3jKCVB/rt2EKAADgWCBMAQAAOECYAgAAcIAwBQAA4ABhCgAAwAHCFAAAgAOEKQAAAAcIUwAAAA4QpgAAABwgTAEAADhAmAIAAHCAMAUAAOAAYQoAAMABwhQAAIADhCkAAAAHCFMAAAAOEKYAAAAcIEwBAAA4QJgCAABwgDAFAADggCfTHegrh9v9Wr+zWZsPBrR+Z5O8bpfy3C553KbTtNdtZIzJdJcBAEAO6rdh6vOGQ7rq0bdCM2+/0WN9jysUrDxuozy3K+l0JHh5w2Wx00e7XrI2POHyrqYj9d0uAiAAAJnWb8PU2KED9OS8aXr/gw81YeKpag8E5Q9Y+QJB+YJWPn9QvkBQ/qBVe7LpJHUj0+3+oA61B7psw+cPyhcMyhewCgRtn32PLqPoKFueJxzOPB1BLj9SFrM8VGY66sfU6ygzScoS65mk6+bFLPe4OYsMAOj/+m2YGlTgVe0pI6WdHtVWlWesH8GgjQar2JDl8wflDwbV7rfyB0NBrKtpnz/chj8c3CJlgVB7kSAX+hpaHl8W1OEjgU5lvkBQbdHp9Ae/ZGGvuyCWLOzt2dWmt4+sV364Xp7HpXyPOzTtjszHLut+eZ7bxSldAEBa9dswlS1cLqN8l1v5Hkn5me5N9wJBmxCwOoJXWzioRcpCgS78NVpmO8rCXyPBrz0QCH/tvK7Pb3Wo3ZdQFpo+1OrX8u2b1R4IyqYp6+V5XHHhLC5wuRMCW7huvrdjWXeBrqMdd5J1Iu11tM2pWgDIfYQpRLldRm6XWwVed6a7ElVXV6fa2lpZa+UPWrWFT7NGXm3+QKgsEJmPWR4IqM0Xv6y75bHrNx7xRdtPXNYeCKZtFM/jMqHr6lwueT2uuGv34qc7PjThcbvkDa/XMd1xitbjipxm7Zj2xlxz53FFruVLsjzcVqRPkXrdLfe4+AAHgOMbYQo5wZiOg3o2jPD5A51DWGzYSgxi7YGg2nxBtQXig2B7+NRtZCQwdK1e6BRv5Lq92OWR6/X8kbox9ZKt15fX7MWKD2nxodDXekSDP3gjbiQvcro3z+OOXqMXudavY3nHaF7i6eK48mi7RnnhUb/IqWJO7QI4FlIKU8aYiyT9XJJb0q+stT9OWH6tpAXh2RZJ/2St/SCdHQWyiSc8UjMgL9M96V4waKNhLDF8+YNW/kDH6Vt/+Hq+2Hr+mA9edCyPBLyY5YFgtK2OQBea3r6zTYMHF6g9YNXuD+hwu18Hj9i44Jl4nZ8/zSEwEsTzYkJbskDmDX/NTwhkkTr5SQJf9AMXrsSRP1d45LGjPM/T/XJu0wLkph7DlDHGLelhSX8nqV7SSmPMS9baj2OqfS7pfGvtAWPMxZIWSjqrLzoMIHUul1GeKxQKMiV0qnZar9YJBjuur4sNWXEBLPqBi4Da/Z0/eJEY1nxJwlu0fng+8kGNdn8g1HbMupFRxb7mdoVHYV2Jp3UTTq+Gy2NvwZJ4arjL071xIc4kOQUcc2sXl0uf7g+oeOuB+E8OR8JmTMDklC+OV6mMTJ0paaO1dpMkGWOelnS5pGiYsta+FVP/HUmj09lJAMcXl8uoIMuu35MUvXYvNrS1+eNH+TqP4IVH+YIxo4DdjBImjux1rBMaBew4xdsx3eoPdDPi2LkPR+Wvb/VcRwqHq/jbr3SM/HXcNDk+lLmj99OLWy+FdryeJO11aqdjBNFN4EMfSCVMVUjaFjNfr+5HnW6U9OdkC4wxt0i6RZJKS0tVV1eXWi8daGlpOSbbQd9g/+U+9mHojdYjqaC7Si6l8QFfJvzq3KC1VkErBSKvoOS3VoFgaN4fjJTbaJ2WQ0fkyS+ILvcFQ8v9wdC83yoU4qLzNjwfkD8YUMBa+YKSvz207hEbUzeynk0+n25GkscVfpnwB2+M5HaFd0H4q9tl5JJkjOQ2oVu9dLxMdNrdRXnccoX+QHApyTITuiY0cRvdLetYHrO9bvreeuSw/s+rS8Mjl5LXFVoX6ZNKmEr2E0/6p40x5ksKhanzki231i5U6BSgampqbG1tbWq9dCDyaTDkJvZf7mMf5r5M7cPISGDkFiptgUD0Pn2xp3Ujp2RjT9nGfmijPfIhjS5u2eILBBWwoQ9sBG3ousFgeNvJyoJBq4C1agvELAvGLwuE1+0oC0bLjtHnQmIYSUfiSjwuE3NLF3fSW7zke9xJ6+Qn1ImWe8O3hUnSTvy6HbeOcfWT28OkEqbqJY2JmR8taUdiJWPMFEm/knSxtXZferoHADhexX2KN0+SvJnuUlrYSNiKCV3RV5Ky2GAXSAh4qdT/6OP1qjzx5LhbvEQ+TRw73zEdvkXM4fa4srbw9YSR6XSInJbN97rDX13xX2OCV7I6+eHyqooSzTh5RFr6dDRSCVMrJZ1kjKmUtF3SXElfi61gjBkr6XlJ11lrN6S9lwAA9BPGhD8YcIy2N7Rpo2rPHpfWNq0NXdfXOZR1DmttMQGst4GuzR/Q4UP+hFAX354k/eM547I7TFlr/caYb0l6TaFbIzxurf3IGHNrePljkn4oaZikR8IX9vmttTV9120AAJApxpjQvd0y+ElhKRTq0vmEjKOVUjC21r4i6ZWEssdipm+SdFN6uwYAANA1Y4zyPZn/1G9W3QHd5/Opvr5era2taWuzpKRE69evT1t7x5OCggKNHj1aXm//uE4BAIC+kFVhqr6+XoMGDdIJJ5yQtvuANDc3a9CgQWlp63hirdW+fftUX1+vysrKTHcHAICsldmTnQlaW1s1bNgwbqiWBYwxGjZsWFpHCQEA6I+yKkxJIkhlEfYFAAA9y7owBQAAkEsIUwmKiooy3QUAAJBDCFMAAAAOZNWn+WL96I8f6eMdTY7bCQQCcrtD96CYNKpY//rlU1Naz1qr73znO/rzn/8sY4y+//3va86cOdq5c6fmzJmjpqYm+f1+Pfroozr33HN14403atWqVTLG6IYbbtD8+fMd9x0AAGS/rA1Tmfb8889rzZo1+uCDD9TQ0KBp06ZpxowZ+t3vfqcLL7xQ3/ve9xQIBHT48GGtWbNG27dv17p16yRJjY2Nme08AAA4ZrI2TKU6gtSTo73P1IoVK3TNNdfI7XartLRU559/vlauXKlp06bphhtukM/n0xVXXKHTTjtN48eP16ZNm3T77bfrkksu0QUXXJCWvgMAgOzHNVNdsF086GfGjBlavny5KioqdN1112nRokUaMmSIPvjgA9XW1urhhx/WTTfxZB0AAI4XhKkuzJgxQ88884wCgYD27t2r5cuX68wzz9SWLVs0cuRI3Xzzzbrxxhv13nvvqaGhQcFgUFdddZXuu+8+vffee5nuPgAAOEay9jRfpl155ZV6++23VV1dLWOMHnjgAZWVlek3v/mNHnzwQXm9XhUVFWnRokXavn275s2bp2AwKEn6z//8zwz3HgAAHCuEqQQtLS2SQnf/fvDBB/Xggw/GLb/++ut1/fXXd1qP0SgAAI5PnOYDAABwgDAFAADgAGEKAADAAcIUAACAA4QpAAAABwhTAAAADhCmAAAAHCBMZYjf7890FwAAQBpk7007//xdaddax80UBvySO/xtllVJF/+4x3WuuOIKbdu2Ta2trbrzzjt1yy236NVXX9U999yjQCCg4cOHa8mSJWppadHtt9+uVatWyRijf/3Xf9VVV12loqKi6M0/n3vuOb388st68skn9Y1vfENDhw7V+++/r9NPP11z5szRXXfdpSNHjqiwsFBPPPGETjnlFAUCAS1YsECvvfaajDG6+eabNWnSJD300EN64YUXJEl/+ctf9Oijj+r55593/DMCAABHL3vDVAY9/vjjGjp0qI4cOaJp06bp8ssv180336zly5ersrJS+/fvlyTdd999Kikp0dq1odB34MCBHtvesGGDFi9eLLfbraamJi1fvlwej0eLFy/WPffcoz/84Q9auHChPv/8c73//vvyeDzav3+/hgwZom9+85vau3evRowYoSeeeELz5s3r058DAADoWfaGqRRGkFJxpLlZgwYN6tU6v/jFL6IjQNu2bdPChQs1Y8YMVVZWSpKGDh0qSVq8eLGefvrp6HpDhgzpse2vfOUrcrvdkqSDBw/q+uuv19/+9jcZY+Tz+aLt3nrrrfJ4PHHbu+666/Tb3/5W8+bN09tvv61Fixb16vsCAADpl71hKkPq6uq0ePFivf322xowYIBqa2tVXV2tTz/9tFNda62MMZ3KY8taW1vjlg0cODA6/YMf/EBf+tKX9MILL2jz5s2qra3ttt158+bpy1/+sgoKCvSVr3wlGrYAAEDmcAF6goMHD2rIkCEaMGCAPvnkE73zzjtqa2vT66+/rs8//1ySoqf5LrjgAj300EPRdSOn+UpLS7V+/XoFg8HoCFdX26qoqJAkPfnkk9HyCy64QI899lj0IvXI9kaNGqVRo0bp3//93/WNb3wjbd8zAAA4eoSpBBdddJH8fr+mTJmiH/zgBzr77LM1YsQILVy4UP/wD/+g6upqzZkzR5L0/e9/XwcOHNDkyZNVXV2tZcuWSZJ+/OMf69JLL9XMmTNVXl7e5ba+853v6O6779b06dMVCASi5TfddJPGjh2rKVOmqLq6Wr/73e+iy6699lqNGTNGkyZN6qOfAAAA6A1jrc3IhmtqauyqVaviytavX6+JEyemdTvNR3HNVDb71re+palTp+rGG288Jtvri33SG3V1ddHTn8hN7MPcxz7Mbey/9DDGrLbW1iRbxkU3OeSMM87QwIED9dOf/jTTXQEAAGGEqRyyevXqTHcBAAAk4JopAAAABwhTAAAADhCmAAAAHCBMAQAAOECYAgAAcIAw5UBRUVGXyzZv3qzJkycfw94AAIBMyNpbI/zkrz/RJ/s/cdxOIBCIPlh4wtAJWnDmAsdtAgAARDAyFWPBggV65JFHovP33nuvfvSjH2nWrFk6/fTTVVVVpRdffLHX7ba2tmrevHmqqqrS1KlTo4+d+eijj3TmmWfqtNNO05QpU/S3v/1Nhw4d0iWXXKLq6mpNnjxZzzzzTNq+PwAAkH5ZOzKVrhGk3jxOZu7cubrrrrt02223SZKeffZZvfrqq5o/f76Ki4vV0NCgs88+W5dddpmMMSn34eGHH5YkrV27Vp988okuuOACbdiwQY899pjuvPNOXXvttWpvb1cgENArr7yiUaNG6U9/+pOk0MOQAQBA9mJkKsbUqVO1Z88e7dixQx988IGGDBmi8vJy3XPPPZoyZYpmz56t7du3a/fu3b1qd8WKFbruuuskSRMmTNC4ceO0YcMGnXPOObr//vv1k5/8RFu2bFFhYaGqqqq0ePFiLViwQG+88YZKSkr64lsFAABpQphKcPXVV+u5557TM888o7lz5+qpp57S3r17tXr1aq1Zs0alpaVqbW3tVZtdPUz6a1/7ml566SUVFhbqwgsv1NKlS3XyySdr9erVqqqq0t13361/+7d/S8e3BQAA+kjWnubLlLlz5+rmm29WQ0ODXn/9dT377LMaOXKkvF6vli1bpi1btvS6zRkzZuipp57SzJkztWHDBm3dulWnnHKKNm3apPHjx+uOO+7Qpk2b9OGHH2rChAkaOnSovv71r6uoqEhPPvlk+r9JAACQNoSpBKeeeqqam5tVUVGh8vJyXXvttfryl7+smpoanXbaaZowYUKv27ztttt06623qqqqSh6PR08++aTy8/P1zDPP6Le//a28Xq/Kysr0wx/+UCtXrtS//Mu/yOVyyev16tFHH+2D7xIAAKQLYSqJtWvXRqeHDx+ut99+O2m9lpaWLts44YQTtG7dOklSQUFB0hGmu+++W3fffXdc2YUXXqgLL7zwKHoNAAAygWumAAAAHGBkyqG1a9dGP6kXkZ+fr3fffTdDPQIAAMcSYcqhqqoqrVmzJtPdAAAAGcJpPgAAAAcIUwAAAA4QpgAAABwgTAEAADhAmHKgqKgo010AAAAZlrWf5tt1//1qW/+J43b8gYD2u92SpPyJE1R2zz2O28w2fr9fHk/W7koAAPo1RqZiLFiwQI888kh0/t5779WPfvQjzZo1S6effrqqqqr04osvptRWS0tLl+stWrRIU6ZMUXV1dfQeVbt379aVV16p6upqVVdX66233tLmzZs1efLk6Hr/9V//pXvvvVeSVFtbq3vuuUfnn3++fv7zn+uPf/yjzjrrLE2dOlWzZ8/W7t27o/2YN2+eqqqqNGXKFP3hD3/Qr3/9a82fPz/a7i9/+Ut9+9vfPuqfGwAAx7OsHc5I1whSc3OzBg0alFLduXPn6q677tJtt90mSXr22Wf16quvav78+SouLlZDQ4POPvtsXXbZZTLGdNtWQUGBXnjhhU7rffzxx/qP//gPvfnmmxo+fLj2798vSbrjjjt0/vnn64UXXlAgEFBLS4sOHDjQ7TYaGxv1+uuvS5IOHDigd955R8YY/epXv9IDDzygn/70p7rvvvtUUlISfUTOgQMHlJeXpylTpuiBBx6Q1+vVE088of/+7/9O6WcEAADiZW2YyoSpU6dqz5492rFjh/bu3ashQ4aovLxc8+fP1/Lly+VyubR9+3bt3r1bZWVl3bZlrdU999zTab2lS5fq6quv1vDhwyVJQ4cOlSQtXbpUixYtkiS53W6VlJT0GKbmzJkTna6vr9ecOXO0c+dOtbe3q7KyUpK0ePFiPf3009F6Q4YMkSTNnDlTL7/8siZOnCifz6eqqqpe/rQAAIBEmOrk6quv1nPPPaddu3Zp7ty5euqpp7R3716tXr1aXq9XJ5xwglpbW3tsp6v1rLU9jmpFeDweBYPB6HzidgcOHBidvv322/Xtb39bl112merq6qKnA7va3k033aT7779fEyZM0Lx581LqDwAA6IxrphLMnTtXTz/9tJ577jldffXVOnjwoEaOHCmv16tly5Zpy5YtKbXT1XqzZs3Ss88+q3379klS9DTfrFmz9Oijj0qSAoGAmpqaVFpaqj179mjfvn1qa2vTyy+/3O32KioqJEm/+c1vouUXXHCBHnrooeh8ZLTrrLPO0rZt2/S73/1O11xzTao/HgAAkIAwleDUU09Vc3OzKioqVF5ermuvvVarVq1STU2NnnrqKU2YMCGldrpa79RTT9X3vvc9nX/++aquro5e+P3zn/9cy5YtU1VVlc444wx99NFH8nq9+uEPf6izzjpLl156abfbvvfee/WVr3xFX/ziF6OnECXp+9//vg4cOKDJkyerurpay5Ytiy776le/qunTp0dP/QEAgN4z1tqMbLimpsauWrUqrmz9+vWaOHFiWrfTmwvQjzeXXnqp5s+fr1mzZnVZpy/2SW/U1dWptrY2Y9uHc+zD3Mc+zG3sv/Qwxqy21tYkW8bI1HGosbFRJ598sgoLC7sNUgAAoGdcgO7Q2rVro/eKisjPz9e7776boR71bPDgwdqwYUOmuwEAQL+QdWGqN592ywZVVVVas2ZNprvRJzJ1ChgAgFySVaf5CgoKtG/fPg7iWcBaq3379qmgoCDTXQEAIKtl1cjU6NGjVV9fr71796atzdbWVgLBUSooKNDo0aMz3Q0AALJaVoUpr9cbvXN3utTV1Wnq1KlpbRMAACAipdN8xpiLjDGfGmM2GmO+m2S5Mcb8Irz8Q2PM6envKgAAQPbpMUwZY9ySHpZ0saRJkq4xxkxKqHaxpJPCr1skPZrmfgIAAGSlVEamzpS00Vq7yVrbLulpSZcn1Llc0iIb8o6kwcaY8jT3FQAAIOukcs1UhaRtMfP1ks5KoU6FpJ2xlYwxtyg0ciVJLcaYT3vV26MzXFLDMdgO+gb7L/exD3Mf+zC3sf/SY1xXC1IJU8lu+pR474JU6shau1DSwhS2mTbGmFVd3f4d2Y/9l/vYh7mPfZjb2H99L5XTfPWSxsTMj5a04yjqAAAA9DuphKmVkk4yxlQaY/IkzZX0UkKdlyT9Y/hTfWdLOmit3ZnYEAAAQH/T42k+a63fGPMtSa9Jckt63Fr7kTHm1vDyxyS9IunvJW2UdFjSvL7rcq8d09OKSDv2X+5jH+Y+9mFuY//1McOjWwAAAI5eVj2bDwAAINcQpgAAABzot2Gqp0fgILsZY8YYY5YZY9YbYz4yxtyZ6T6h94wxbmPM+8aYlzPdF/SeMWawMeY5Y8wn4X+L52S6T+gdY8z88HvoOmPM740xBZnuU3/UL8NUio/AQXbzS/pna+1ESWdL+ib7MCfdKWl9pjuBo/ZzSa9aaydIqhb7MqcYYyok3SGpxlo7WaEPkc3NbK/6p34ZppTaI3CQxay1O62174WnmxV6E6/IbK/QG8aY0ZIukfSrTPcFvWeMKZY0Q9KvJcla226tbcxop3A0PJIKjTEeSQPEPSD7RH8NU1093gY5yBhzgqSpkt7NcFfQOz+T9B1JwQz3A0dnvKS9kp4In6r9lTFmYKY7hdRZa7dL+i9JWxV6vNtBa+3/zWyv+qf+GqZSerwNsp8xpkjSHyTdZa1tynR/kBpjzKWS9lhrV2e6LzhqHkmnS3rUWjtV0iFJXH+aQ4wxQxQ6K1MpaZSkgcaYr2e2V/1Tfw1TPN6mHzDGeBUKUk9Za5/PdH/QK9MlXWaM2azQafaZxpjfZrZL6KV6SfXW2siI8HMKhSvkjtmSPrfW7rXW+iQ9L+ncDPepX+qvYSqVR+AgixljjELXaqy31v5/me4Pesdae7e1drS19gSF/v0ttdbyF3EOsdbukrTNGHNKuGiWpI8z2CX03lZJZxtjBoTfU2eJDxH0iR4fJ5OLunoEToa7hd6ZLuk6SWuNMWvCZfdYa1/JXJeA487tkp4K/1G6Sdn1qDD0wFr7rjHmOUnvKfQJ6ffFo2X6BI+TAQAAcKC/nuYDAAA4JghTAAAADhCmAAAAHCBMAQAAOECYAgAAcIAwBQAA4ABhCgAAwIH/B6uo2/Gqqw42AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model.history.history).plot(figsize=(10, 7))\n",
    "plt.grid(True)\n",
    "plt.ylim([0,1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the val_accuarcy is still increasing, we can keep on training. But we'll stop here for now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 3ms/step - loss: 60.9790 - accuracy: 0.8605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[60.979007720947266, 0.8604999780654907]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did made some progress! ):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the Model to Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harik\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! It classifies all the first three images correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a Regression MLP Using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "housing = fetch_california_housing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train_full, y_train_full)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, let's first use a linear model to train on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "X_train_full_scaled = scaler.fit_transform(X_train_full)\n",
    "X_test_lin = scaler.transform(X_test)\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_full_scaled, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6063345386385339"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.score(X_test_lin, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7192051325828581"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = lin_reg.predict(X_test_lin)\n",
    "(mean_squared_error(y_pred, y_test))**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, the root mean square error is 0.719. Now, lets train a simple MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 28, 30)            870       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 28, 1)             31        \n",
      "=================================================================\n",
      "Total params: 901\n",
      "Trainable params: 901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 6s 9ms/step - loss: 0.9186 - mae: 0.6640 - val_loss: 2.6933 - val_mae: 0.6257\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 1.7237 - mae: 0.6084 - val_loss: 0.5054 - val_mae: 0.5139\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4748 - mae: 0.4971 - val_loss: 0.4664 - val_mae: 0.4851\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.4466 - mae: 0.4803 - val_loss: 0.4519 - val_mae: 0.4768\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4305 - mae: 0.4691 - val_loss: 0.4332 - val_mae: 0.4603\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.4186 - mae: 0.4601 - val_loss: 0.4226 - val_mae: 0.4618\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4152 - mae: 0.4569 - val_loss: 0.4198 - val_mae: 0.4635\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4053 - mae: 0.4518 - val_loss: 0.4142 - val_mae: 0.4499\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4275 - mae: 0.4570 - val_loss: 0.4228 - val_mae: 0.4557\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.4059 - mae: 0.4511 - val_loss: 0.4074 - val_mae: 0.4425\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3939 - mae: 0.4435 - val_loss: 0.3983 - val_mae: 0.4398\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3906 - mae: 0.4399 - val_loss: 0.3943 - val_mae: 0.4405\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3854 - mae: 0.4380 - val_loss: 0.3887 - val_mae: 0.4377\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3845 - mae: 0.4376 - val_loss: 0.4610 - val_mae: 0.4504\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3997 - mae: 0.4414 - val_loss: 0.3958 - val_mae: 0.4345\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3746 - mae: 0.4318 - val_loss: 0.3802 - val_mae: 0.4326\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3693 - mae: 0.4283 - val_loss: 0.3733 - val_mae: 0.4299\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3683 - mae: 0.4274 - val_loss: 0.3734 - val_mae: 0.4306\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3634 - mae: 0.4244 - val_loss: 0.3666 - val_mae: 0.4219\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3591 - mae: 0.4206 - val_loss: 0.3673 - val_mae: 0.4229\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"sgd\", loss=\"mse\", metrics=\"mae\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=20,validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5898363690310889"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mean_squared_error(y_test, y_pred))**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hurray! The score improved from 0.719 to 0.590."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Complex Models Using the Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One example of a non-sequential neural network is a Wide & Deep neural network.\n",
    "It connects all or part of the inputs directly to the output layer, as shown in\n",
    "the figure. This architecture makes it possible for the neural network to learn both\n",
    "deep patterns (using the deep path) and simple rules (through the short path). In\n",
    "contrast, a regular MLP forces all the data to flow through the full stack of layers, thus\n",
    "simple patterns in the data may end up being distorted by this sequence of transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<figcaption><h4>Wide and Deep Neural Network</h4></figcaption>\n",
    "<img src = \"img/10_11.png\">\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it is done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 28, 28)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 28, 30)       870         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 28, 30)       930         dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 58)       0           input_4[0][0]                    \n",
      "                                                                 dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 28, 1)        59          concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,859\n",
      "Trainable params: 1,859\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce44b17c45080b8f56a19c9450d52461d624c968fcd959bb1916985c5ffa2b94"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
